# OmniAgent ç”¨æˆ·æŒ‡å—

## ç®€ä»‹

OmniAgent æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¯é…ç½®åº”ç”¨ç¨‹åºï¼Œèƒ½å¤Ÿè¿æ¥å¤šä¸ª LLM æä¾›å•†ã€MCP æœåŠ¡å™¨ï¼Œå¹¶åŒæ—¶ä½œä¸º A2A æœåŠ¡å™¨å¯¹å¤–æä¾›æœåŠ¡ã€‚

## æ¶æ„æ¦‚è§ˆ

æœ‰å…³ OmniAgent çš„æ¶æ„ä¿¡æ¯ï¼Œè¯·å‚é˜…ä»¥ä¸‹æ–‡æ¡£ï¼š

- [å½“å‰æ¶æ„](current_architecture.md) - ç°æœ‰çš„å®ç°æ¶æ„
- [ç†æƒ³æ¶æ„](ideal_architecture.md) - æœªæ¥çš„å‘å±•æ–¹å‘
- [æ¶æ„å¯¹æ¯”](architecture_comparison.md) - å½“å‰ä¸ç†æƒ³æ¶æ„çš„å·®å¼‚åˆ†æ

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/your-username/omni-agent.git
cd omni-agent

# å®‰è£…ä¾èµ–
cargo build --release
```

### 2. é…ç½® LLM æä¾›å•†

#### ä½¿ç”¨ Claude
```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export ANTHROPIC_API_KEY="your-anthropic-api-key"
```

#### ä½¿ç”¨ OpenAI
```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export OPENAI_API_KEY="your-openai-api-key"
```

#### ä½¿ç”¨ Google Gemini
```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export GOOGLE_API_KEY="your-google-api-key"
```

### 3. é…ç½®æ–‡ä»¶

å¤åˆ¶ç¤ºä¾‹é…ç½®æ–‡ä»¶ï¼š

```bash
cp config.example.json config.json
```

ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼š

```json
{
  "llm": {
    "provider": "claude",
    "api_key": "your-anthropic-api-key",
    "model": "claude-3-haiku-20240307",
    "use_mock": false
  }
}
```

### 4. å¯åŠ¨åº”ç”¨

```bash
# ç›´æ¥è¿è¡Œ
cargo run --release

# æˆ–ä½¿ç”¨é…ç½®æ–‡ä»¶
OMNI_AGENT_CONFIG=my-config.json cargo run --release
```

## ğŸ“‹ å®Œæ•´é…ç½®ç¤ºä¾‹

### è¿æ¥å¤šä¸ª MCP æœåŠ¡å™¨

```json
{
  "mcp": {
    "enabled": true,
    "servers": {
      "weather": {
        "name": "Weather Service",
        "url": "http://localhost:8081",
        "enabled": true
      },
      "calculator": {
        "name": "Calculator Service",
        "url": "http://localhost:8082",
        "enabled": true
      }
    }
  }
}
```

### è¿æ¥å¤šä¸ª A2A æœåŠ¡å™¨

```json
{
  "a2a": {
    "enabled": true,
    "servers": {
      "assistant1": {
        "name": "Research Assistant",
        "url": "http://localhost:8083",
        "auth_token": "optional-token",
        "enabled": true
      },
      "assistant2": {
        "name": "Code Assistant",
        "url": "http://localhost:8084",
        "enabled": true
      }
    }
  }
}
```

### å®Œæ•´é…ç½®ç¤ºä¾‹

```json
{
  "server": {
    "port": 8080,
    "host": "0.0.0.0"
  },
  "llm": {
    "provider": "claude",
    "api_key": "your-key",
    "model": "claude-3-haiku-20240307",
    "temperature": 0.7,
    "max_tokens": 1000,
    "use_mock": false
  },
  "mcp": {
    "enabled": true,
    "servers": {
      "weather": {
        "name": "Weather MCP",
        "url": "http://localhost:8081",
        "timeout": 30,
        "enabled": true
      }
    }
  },
  "a2a": {
    "enabled": true,
    "servers": {
      "assistant": {
        "name": "External Agent",
        "url": "http://localhost:8083",
        "timeout": 30,
        "enabled": true
      }
    }
  }
}
```

## ğŸ”§ ç¯å¢ƒå˜é‡é…ç½®

| å˜é‡å | æè¿° | ç¤ºä¾‹ |
|--------|------|------|
| `ANTHROPIC_API_KEY` | Claude API å¯†é’¥ | `sk-ant-...` |
| `OPENAI_API_KEY` | OpenAI API å¯†é’¥ | `sk-...` |
| `GOOGLE_API_KEY` | Google AI API å¯†é’¥ | `AIza...` |
| `PORT` | æœåŠ¡å™¨ç«¯å£ | `8080` |
| `OMNI_AGENT_CONFIG` | é…ç½®æ–‡ä»¶è·¯å¾„ | `config.json` |
| `USE_MOCK` | ä½¿ç”¨ mock æ¨¡å¼ | `true` æˆ– `false` |
| `LOG_LEVEL` | æ—¥å¿—çº§åˆ« | `info`, `debug`, `error` |

## ğŸŒ ä½¿ç”¨åº”ç”¨

### 1. å¯åŠ¨åè®¿é—®

åº”ç”¨å¯åŠ¨åï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è®¿é—®ï¼š

- **Web ç•Œé¢**: http://localhost:8080
- **å¥åº·æ£€æŸ¥**: http://localhost:8080/health
- **èƒ½åŠ›æ¸…å•**: http://localhost:8080/manifest
- **å‘é€æ¶ˆæ¯**: POST http://localhost:8080/messages

### 2. å‘é€æ¶ˆæ¯ç¤ºä¾‹

```bash
# å‘é€ç®€å•æ¶ˆæ¯
curl -X POST http://localhost:8080/messages \
  -H "Content-Type: application/json" \
  -d '{
    "sender": "user",
    "recipient": "OmniAgent",
    "content": {
      "type": "text",
      "text": "Hello, what can you do?"
    }
  }'
```

### 3. æ£€æŸ¥çŠ¶æ€

```bash
# æŸ¥çœ‹æ•´ä½“çŠ¶æ€
curl http://localhost:8080/health

# æŸ¥çœ‹èƒ½åŠ›æ¸…å•
curl http://localhost:8080/manifest
```

## ğŸ”„ åŠ¨æ€é…ç½®

### è¿è¡Œæ—¶æ·»åŠ  MCP æœåŠ¡å™¨

é€šè¿‡é…ç½®æ–‡ä»¶ï¼Œå¯ä»¥åœ¨ä¸é‡å¯åº”ç”¨çš„æƒ…å†µä¸‹æ·»åŠ æ–°çš„ MCP æœåŠ¡å™¨ã€‚

### è¿è¡Œæ—¶åˆ‡æ¢ LLM æä¾›å•†

é€šè¿‡ä¿®æ”¹é…ç½®æ–‡ä»¶å¹¶é‡å¯åº”ç”¨ï¼Œå¯ä»¥åˆ‡æ¢ LLM æä¾›å•†ã€‚

## ğŸ› è°ƒè¯•æ¨¡å¼

### ä½¿ç”¨ Mock æ¨¡å¼

```json
{
  "llm": {
    "use_mock": true
  }
}
```

### è¯¦ç»†æ—¥å¿—

```bash
LOG_LEVEL=debug cargo run --release
```

## ğŸ“Š ç›‘æ§å’Œæ—¥å¿—

### æ—¥å¿—æ ¼å¼

æ”¯æŒ JSON æ ¼å¼æ—¥å¿—ï¼š

```json
{
  "timestamp": "2024-12-20T10:30:00Z",
  "level": "INFO",
  "message": "Connected to MCP server",
  "server": "weather"
}
```

### å¥åº·æ£€æŸ¥

åº”ç”¨æä¾›å¥åº·æ£€æŸ¥ç«¯ç‚¹ï¼š

```bash
curl http://localhost:8080/health
```

è¿”å›ç¤ºä¾‹ï¼š

```json
{
  "status": "healthy",
  "timestamp": "2024-12-20T10:30:00Z",
  "services": {
    "llm": {
      "provider": "claude",
      "connected": true,
      "mock_mode": false
    },
    "mcp": {
      "connected_servers": 2,
      "total_servers": 2
    },
    "a2a": {
      "connected_servers": 1,
      "total_servers": 1,
      "port": 8080
    }
  }
}
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **API å¯†é’¥æ— æ•ˆ**
   - æ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®è®¾ç½®
   - éªŒè¯ API å¯†é’¥æ˜¯å¦æœ‰æ•ˆ

2. **MCP æœåŠ¡å™¨è¿æ¥å¤±è´¥**
   - æ£€æŸ¥æœåŠ¡å™¨ URL æ˜¯å¦æ­£ç¡®
   - éªŒè¯æœåŠ¡å™¨æ˜¯å¦è¿è¡Œ
   - æ£€æŸ¥ç½‘ç»œè¿æ¥

3. **A2A æœåŠ¡å™¨è¿æ¥å¤±è´¥**
   - æ£€æŸ¥æœåŠ¡å™¨ URL æ˜¯å¦æ­£ç¡®
   - éªŒè¯è®¤è¯ä»¤ç‰Œï¼ˆå¦‚æœéœ€è¦ï¼‰
   - æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦è¿è¡Œ

4. **ç«¯å£è¢«å ç”¨**
   - ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„ç«¯å£
   - æˆ–ä½¿ç”¨ç¯å¢ƒå˜é‡ `PORT=8081 cargo run`

### è°ƒè¯•ä¿¡æ¯

ä½¿ç”¨è¯¦ç»†æ—¥å¿—æ¨¡å¼è·å–æ›´å¤šä¿¡æ¯ï¼š

```bash
LOG_LEVEL=debug cargo run --release
```

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### ä¸ªäºº AI åŠ©æ‰‹
- é…ç½® Claude ä½œä¸º LLM
- è¿æ¥å¤©æ°”ã€è®¡ç®—å™¨ MCP æœåŠ¡å™¨
- ä½œä¸º A2A æœåŠ¡å™¨ä¾›å…¶ä»–åº”ç”¨è°ƒç”¨

### ä¼ä¸šçº§éƒ¨ç½²
- é…ç½®å¤šä¸ª LLM æä¾›å•†
- è¿æ¥å†…éƒ¨ MCP æœåŠ¡å™¨
- ä½œä¸º A2A ç½‘å…³åè°ƒå¤šä¸ªä»£ç†

### å¼€å‘æµ‹è¯•
- ä½¿ç”¨ Mock æ¨¡å¼è¿›è¡Œå¼€å‘
- è¿æ¥æœ¬åœ° MCP æœåŠ¡å™¨
- å¿«é€ŸåŸå‹éªŒè¯